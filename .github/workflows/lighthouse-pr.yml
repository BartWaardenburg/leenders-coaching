name: 'Lighthouse (PR)'

on: deployment_status

concurrency:
  group: lhci-${{ github.ref }}
  cancel-in-progress: true

env:
  NODE_VERSION: '22'

jobs:
  lighthouse:
    name: 'Lighthouse CI (Preview)'
    runs-on: ubuntu-latest
    timeout-minutes: 25
    permissions:
      contents: read
      deployments: read
      pull-requests: write
      issues: write
    # Only run for successful leenders-coaching deployments (not studio)
    if: |
      github.event.deployment_status.state == 'success' &&
      contains(github.event.deployment.environment, 'leenders-coaching') &&
      !contains(github.event.deployment.environment, 'studio')

    steps:
      - name: 'ğŸ”„ Checkout repository'
        uses: actions/checkout@v5
        with:
          fetch-depth: 0

      - name: 'ğŸ”§ Setup Node.js'
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: 'ğŸ”‘ Verify Vercel API authentication'
        run: |
          if [ -n "${{ secrets.VERCEL_TOKEN }}" ]; then
            echo "ğŸ” Testing Vercel API authentication..."
            
            # Test API access with user info
            user_response=$(curl -s -H "Authorization: Bearer ${{ secrets.VERCEL_TOKEN }}" \
              "https://api.vercel.com/v2/user" || echo "AUTH_FAILED")
            
            if [ "$user_response" = "AUTH_FAILED" ]; then
              echo "âŒ Vercel API authentication failed"
              echo "âš ï¸ This may cause issues accessing protected preview deployments"
            else
              username=$(echo "$user_response" | jq -r '.user.username // "unknown"')
              echo "âœ… Vercel API authentication successful"
              echo "ğŸ“‹ Authenticated as: $username"
            fi
          else
            echo "âš ï¸ No VERCEL_TOKEN available - preview protection bypass unavailable"
          fi

      - name: 'ğŸ” Get Vercel preview URL with API authentication'
        id: get_url
        run: |
          set -euo pipefail

          echo "ğŸ‰ Triggered by successful Vercel deployment!"
          echo "Environment: ${{ github.event.deployment.environment }}"
          echo "State: ${{ github.event.deployment_status.state }}"

          # Extract deployment ID from the deployment event
          deployment_id="${{ github.event.deployment.id }}"
          echo "ğŸ” Deployment ID: $deployment_id"

          # Get deployment details using Vercel API
          if [ -n "${{ secrets.VERCEL_TOKEN }}" ] && [ -n "${{ secrets.VERCEL_PROJECT_ID }}" ]; then
            echo "ğŸ”‘ Using Vercel API to get deployment details..."
            echo "ğŸ“‹ Project ID: ${{ secrets.VERCEL_PROJECT_ID }}"
            echo "ğŸ“‹ Team ID: ${{ secrets.VERCEL_ORG_ID }}"
            
            # Try multiple API approaches to get the deployment URL
            
            # Method 1: Direct deployment lookup
            echo "ğŸ” Method 1: Direct deployment API call..."
            vercel_response=$(curl -s -H "Authorization: Bearer ${{ secrets.VERCEL_TOKEN }}" \
              "https://api.vercel.com/v13/deployments/$deployment_id" || echo "API_FAILED")
            
            if [ "$vercel_response" != "API_FAILED" ]; then
              echo "âœ… Got deployment response"
              # Debug: Show partial response (first 200 chars)
              echo "ğŸ“‹ Response preview: $(echo "$vercel_response" | cut -c1-200)..."
              
              api_url=$(echo "$vercel_response" | jq -r '.url // empty')
              if [ -n "$api_url" ] && [ "$api_url" != "null" ] && [ "$api_url" != "empty" ]; then
                deployment_url="https://$api_url"
                echo "âœ… Got URL from direct API: $deployment_url"
              else
                echo "âš ï¸ No URL in direct API response"
                
                # Method 2: List deployments for project
                echo "ğŸ” Method 2: Listing project deployments..."
                list_url="https://api.vercel.com/v6/deployments?projectId=${{ secrets.VERCEL_PROJECT_ID }}&limit=10"
                if [ -n "${{ secrets.VERCEL_ORG_ID }}" ]; then
                  list_url="$list_url&teamId=${{ secrets.VERCEL_ORG_ID }}"
                fi
                
                deployments_response=$(curl -s -H "Authorization: Bearer ${{ secrets.VERCEL_TOKEN }}" \
                  "$list_url" || echo "LIST_FAILED")
                
                if [ "$deployments_response" != "LIST_FAILED" ]; then
                  # Find our deployment in the list
                  found_url=$(echo "$deployments_response" | jq -r --arg id "$deployment_id" \
                    '.deployments[] | select(.uid == $id) | .url // empty')
                  
                  if [ -n "$found_url" ] && [ "$found_url" != "null" ] && [ "$found_url" != "empty" ]; then
                    deployment_url="https://$found_url"
                    echo "âœ… Got URL from deployments list: $deployment_url"
                  else
                    echo "âš ï¸ Deployment not found in list, using event URL"
                    deployment_url="${{ github.event.deployment_status.environment_url }}"
                  fi
                else
                  echo "âš ï¸ Failed to list deployments, using event URL"
                  deployment_url="${{ github.event.deployment_status.environment_url }}"
                fi
              fi
            else
              echo "âš ï¸ Direct API call failed, using deployment event URL"
              deployment_url="${{ github.event.deployment_status.environment_url }}"
            fi
          else
            echo "âš ï¸ Missing VERCEL_TOKEN or VERCEL_PROJECT_ID secrets, using deployment event URL"
            deployment_url="${{ github.event.deployment_status.environment_url }}"
          fi

          if [ -z "$deployment_url" ] || [ "$deployment_url" = "null" ]; then
            echo "âŒ No deployment URL found"
            echo "Debug info:"
            echo "  Deployment ID: $deployment_id"
            echo "  Environment: ${{ github.event.deployment.environment }}"
            echo "  State: ${{ github.event.deployment_status.state }}"
            exit 1
          fi

          echo "ğŸ” Raw deployment URL: $deployment_url"

          # Check if this is a Vercel redirect URL and extract the real preview URL
          if [[ "$deployment_url" == *"vercel.com/login"* ]] || [[ "$deployment_url" == *"sso-api"* ]]; then
            echo "âš ï¸  Detected Vercel redirect URL, extracting preview URL..."
            
            # Extract URL from the redirect (URL encoded in the 'url' parameter)
            if [[ "$deployment_url" =~ url%3D([^&]*) ]]; then
              encoded_url="${BASH_REMATCH[1]}"
              # URL decode the preview URL
              preview_url=$(echo "$encoded_url" | sed 's/%3A/:/g; s/%2F/\//g; s/%3F/?/g; s/%3D/=/g; s/%26/\&/g')
              echo "ğŸ”§ Extracted preview URL: $preview_url"
            else
              echo "âŒ Could not extract preview URL from redirect"
              echo "   Redirect URL: $deployment_url"
              exit 1
            fi
          else
            # Direct preview URL
            preview_url="$deployment_url"
            echo "âœ… Direct preview URL: $preview_url"
          fi

          # Validate the preview URL
          if [[ "$preview_url" =~ ^https?://.*\.vercel\.app/?.*$ ]]; then
            echo "âœ… Valid Vercel preview URL confirmed"
            echo "preview-url=$preview_url" >> $GITHUB_OUTPUT
          else
            echo "âŒ Invalid preview URL format: $preview_url"
            echo "   Expected: https://something.vercel.app"
            exit 1
          fi

      - name: 'ğŸ§ª Test preview URL accessibility'
        run: |
          preview_url="${{ steps.get_url.outputs.preview-url }}"
          echo "ğŸ” Testing preview URL accessibility: $preview_url"

          # Set up authentication headers if Vercel token is available
          if [ -n "${{ secrets.VERCEL_TOKEN }}" ]; then
            auth_header="-H 'Authorization: Bearer ${{ secrets.VERCEL_TOKEN }}'"
            echo "ğŸ”‘ Using Vercel token for authenticated requests"
          else
            auth_header=""
            echo "â„¹ï¸ No Vercel token available, using unauthenticated requests"
          fi

          # Check if URL redirects to login page
          response=$(curl -sL --max-time 30 --max-redirs 5 $auth_header "$preview_url" || echo "CURL_FAILED")
          final_url=$(curl -sLI --max-time 30 --max-redirs 5 $auth_header "$preview_url" 2>/dev/null | grep -i "^location:" | tail -1 | cut -d' ' -f2- | tr -d '\r\n' || echo "NO_REDIRECT")

          echo "ğŸ” Final URL after redirects: $final_url"

          if [[ "$final_url" == *"vercel.com/login"* ]] || [[ "$final_url" == *"sso-api"* ]]; then
            echo "âŒ Preview URL still redirects to Vercel login page!"
            echo "   This means your preview deployment requires additional authentication."
            echo ""
            echo "ğŸ“ Possible solutions:"
            echo "   1. Disable Preview Deployment Protection in Vercel:"
            echo "      Settings â†’ General â†’ Preview Deployment Protection â†’ Set to 'Off'"
            echo "   2. Or ensure VERCEL_TOKEN has proper permissions"
            echo ""
            echo "ğŸš¨ LIGHTHOUSE WILL FAIL - Testing protected pages"
            exit 1
          elif [[ "$response" == "CURL_FAILED" ]]; then
            echo "âŒ Preview URL is not accessible (network error)"
            echo "   URL: $preview_url"
            exit 1
          elif echo "$response" | grep -qi "404\|not found"; then
            echo "âš ï¸ Preview URL returns 404 - deployment might not be complete"
            echo "   URL: $preview_url"
          else
            echo "âœ… Preview URL is accessible and serves content"
            # Check if we got actual content or still a login page
            if echo "$response" | grep -qi "vercel.*login\|sign.*in\|authenticate"; then
              echo "âš ï¸ Response seems to contain login-related content, but proceeding..."
            fi
          fi

      - name: 'ğŸš€ Run Lighthouse CI'
        id: lhci
        uses: treosh/lighthouse-ci-action@v12
        with:
          urls: |
            ${{ steps.get_url.outputs.preview-url }}
            ${{ steps.get_url.outputs.preview-url }}/over-mij
            ${{ steps.get_url.outputs.preview-url }}/aanpak
            ${{ steps.get_url.outputs.preview-url }}/coaching
            ${{ steps.get_url.outputs.preview-url }}/contact
          configPath: packages/leenders-coaching-nl/lighthouserc.ci.cjs
          budgetPath: packages/leenders-coaching-nl/budget.json
          uploadArtifacts: true
          temporaryPublicStorage: true
        env:
          LHCI_GITHUB_APP_TOKEN: ${{ secrets.LHCI_GITHUB_APP_TOKEN }}
          # Pass Vercel token to potentially bypass preview protection
          VERCEL_TOKEN: ${{ secrets.VERCEL_TOKEN }}

      - name: 'ğŸ“Š Parse Lighthouse results'
        id: parse_results
        if: always()
        run: |
          # Install bc for floating point calculations
          sudo apt-get update && sudo apt-get install -y bc

          # Parse assertion results to extract key metrics
          results_file="${{ steps.lhci.outputs.resultsPath }}/assertion-results.json"

          if [ -f "$results_file" ]; then
            echo "âœ… Found assertion results file"
            
            # Extract overall status
            overall_status=$(jq -r 'if any(.level == "error") then "âŒ FAILED" else "âœ… PASSED" end' "$results_file")
            echo "overall_status=$overall_status" >> $GITHUB_OUTPUT
            
            # Count assertions by level
            error_count=$(jq '[.[] | select(.level == "error")] | length' "$results_file")
            warn_count=$(jq '[.[] | select(.level == "warn")] | length' "$results_file")
            pass_count=$(jq '[.[] | select(.level == "pass")] | length' "$results_file")
            
            echo "error_count=$error_count" >> $GITHUB_OUTPUT
            echo "warn_count=$warn_count" >> $GITHUB_OUTPUT
            echo "pass_count=$pass_count" >> $GITHUB_OUTPUT
            
            # Extract key metrics for summary (if available)
            performance_score=$(jq -r '[.[] | select(.auditId == "categories:performance")] | if length > 0 then .[0].actual else "N/A" end' "$results_file")
            accessibility_score=$(jq -r '[.[] | select(.auditId == "categories:accessibility")] | if length > 0 then .[0].actual else "N/A" end' "$results_file")
            seo_score=$(jq -r '[.[] | select(.auditId == "categories:seo")] | if length > 0 then .[0].actual else "N/A" end' "$results_file")
            best_practices_score=$(jq -r '[.[] | select(.auditId == "categories:best-practices")] | if length > 0 then .[0].actual else "N/A" end' "$results_file")
            
            # Extract Core Web Vitals
            fcp=$(jq -r '[.[] | select(.auditId == "first-contentful-paint")] | if length > 0 then .[0].actual else "N/A" end' "$results_file")
            lcp=$(jq -r '[.[] | select(.auditId == "largest-contentful-paint")] | if length > 0 then .[0].actual else "N/A" end' "$results_file")
            cls=$(jq -r '[.[] | select(.auditId == "cumulative-layout-shift")] | if length > 0 then .[0].actual else "N/A" end' "$results_file")
            
            # Check budget violations (these will be in assertion results as 'error' level)
            budget_violations=$(jq '[.[] | select(.level == "error" and (.auditId | contains("resource-summary") or contains("performance-budget")))] | length' "$results_file")
            
            # Debug: Log first few results to understand the structure
            echo "ğŸ” First 3 assertion results:"
            jq -r '.[0:3] | .[] | "  - \(.auditId): \(.level) (actual: \(.actual))"' "$results_file" || echo "  No results to display"
            
            echo "performance_score=$performance_score" >> $GITHUB_OUTPUT
            echo "accessibility_score=$accessibility_score" >> $GITHUB_OUTPUT
            echo "seo_score=$seo_score" >> $GITHUB_OUTPUT
            echo "best_practices_score=$best_practices_score" >> $GITHUB_OUTPUT
            echo "fcp=$fcp" >> $GITHUB_OUTPUT
            echo "lcp=$lcp" >> $GITHUB_OUTPUT
            echo "cls=$cls" >> $GITHUB_OUTPUT
            echo "budget_violations=$budget_violations" >> $GITHUB_OUTPUT
            
            # Generate timestamp
            timestamp=$(date -u '+%Y-%m-%d %H:%M:%S UTC')
            echo "timestamp=$timestamp" >> $GITHUB_OUTPUT
            
            # Format scores for display
            format_score() {
              if [ "$1" != "N/A" ] && [ "$1" != "null" ]; then
                printf "%.0f" $(echo "$1 * 100" | bc -l)
              else
                echo "N/A"
              fi
            }
            
            perf_display=$(format_score "$performance_score")
            a11y_display=$(format_score "$accessibility_score")
            seo_display=$(format_score "$seo_score")
            bp_display=$(format_score "$best_practices_score")
            
            echo "perf_display=$perf_display" >> $GITHUB_OUTPUT
            echo "a11y_display=$a11y_display" >> $GITHUB_OUTPUT
            echo "seo_display=$seo_display" >> $GITHUB_OUTPUT
            echo "bp_display=$bp_display" >> $GITHUB_OUTPUT
            
            # Parse links output for clean formatting
            links_output="${{ steps.lhci.outputs.links }}"
            if [ "$links_output" != "" ] && [ "$links_output" != "null" ]; then
              # Try to extract first URL from JSON if it's JSON format
              first_url=$(echo "$links_output" | jq -r 'values[0]' 2>/dev/null || echo "$links_output")
              echo "formatted_links=$first_url" >> $GITHUB_OUTPUT
            else
              echo "formatted_links=" >> $GITHUB_OUTPUT
            fi
            
          else
            echo "âš ï¸ No assertion results file found"
            echo "overall_status=âš ï¸ NO RESULTS" >> $GITHUB_OUTPUT
            echo "error_count=0" >> $GITHUB_OUTPUT
            echo "warn_count=0" >> $GITHUB_OUTPUT
            echo "pass_count=0" >> $GITHUB_OUTPUT
            echo "formatted_links=" >> $GITHUB_OUTPUT
          fi

      - name: 'ğŸ” Get PR number from deployment'
        id: get_pr
        run: |
          # Get PR number from deployment context using GitHub API
          pr_number=$(curl -s -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
            "https://api.github.com/repos/${{ github.repository }}/deployments/${{ github.event.deployment.id }}" \
            | jq -r '.payload.pull_request.number // empty')

          if [ -n "$pr_number" ] && [ "$pr_number" != "null" ]; then
            echo "pr_number=$pr_number" >> $GITHUB_OUTPUT
            echo "âœ… Found PR number: $pr_number"
          else
            # Fallback: try to extract from deployment environment or ref
            ref="${{ github.event.deployment.ref }}"
            if [[ "$ref" =~ refs/pull/([0-9]+)/merge ]]; then
              pr_number="${BASH_REMATCH[1]}"
              echo "pr_number=$pr_number" >> $GITHUB_OUTPUT
              echo "âœ… Extracted PR number from ref: $pr_number"
            else
              echo "âš ï¸ Could not determine PR number"
              echo "pr_number=" >> $GITHUB_OUTPUT
            fi
          fi

          # Debug: Show all available context
          echo "ğŸ” Debug: Available context:"
          echo "  Deployment ID: ${{ github.event.deployment.id }}"
          echo "  Deployment Ref: ${{ github.event.deployment.ref }}"
          echo "  Repository: ${{ github.repository }}"
          echo "  Event Name: ${{ github.event_name }}"
          echo "  Final PR Number: $pr_number"

      - name: 'ğŸ’¬ Post detailed Lighthouse comment'
        if: always() && steps.get_pr.outputs.pr_number != ''
        uses: marocchino/sticky-pull-request-comment@v2
        with:
          header: lighthouse-report
          number: ${{ steps.get_pr.outputs.pr_number }}
          message: |
            ## ğŸš€ Lighthouse Performance Report

            **Preview URL:** ${{ steps.get_url.outputs.preview-url }}
            **Status:** ${{ steps.parse_results.outputs.overall_status }}
            **Generated:** ${{ steps.parse_results.outputs.timestamp }}

            ### ğŸ“Š Performance Scores

            | Category | Score | Status |
            |----------|-------|--------|
            | ğŸš€ Performance | ${{ steps.parse_results.outputs.perf_display != 'N/A' && format('{0}/100', steps.parse_results.outputs.perf_display) || 'N/A' }} | ${{ steps.parse_results.outputs.perf_display != 'N/A' && (steps.parse_results.outputs.perf_display >= '80' && 'âœ…' || (steps.parse_results.outputs.perf_display >= '50' && 'âš ï¸' || 'âŒ')) || 'â“' }} |
            | â™¿ Accessibility | ${{ steps.parse_results.outputs.a11y_display != 'N/A' && format('{0}/100', steps.parse_results.outputs.a11y_display) || 'N/A' }} | ${{ steps.parse_results.outputs.a11y_display != 'N/A' && (steps.parse_results.outputs.a11y_display >= '95' && 'âœ…' || (steps.parse_results.outputs.a11y_display >= '80' && 'âš ï¸' || 'âŒ')) || 'â“' }} |
            | ğŸ” SEO | ${{ steps.parse_results.outputs.seo_display != 'N/A' && format('{0}/100', steps.parse_results.outputs.seo_display) || 'N/A' }} | ${{ steps.parse_results.outputs.seo_display != 'N/A' && (steps.parse_results.outputs.seo_display >= '90' && 'âœ…' || (steps.parse_results.outputs.seo_display >= '70' && 'âš ï¸' || 'âŒ')) || 'â“' }} |
            | âš¡ Best Practices | ${{ steps.parse_results.outputs.bp_display != 'N/A' && format('{0}/100', steps.parse_results.outputs.bp_display) || 'N/A' }} | ${{ steps.parse_results.outputs.bp_display != 'N/A' && (steps.parse_results.outputs.bp_display >= '90' && 'âœ…' || (steps.parse_results.outputs.bp_display >= '70' && 'âŒ')) || 'â“' }} |

            ### âš¡ Core Web Vitals

            | Metric | Value | Target | Status |
            |--------|-------|--------|--------|
            | ğŸ¨ First Contentful Paint | ${{ steps.parse_results.outputs.fcp != 'N/A' && format('{0}ms', steps.parse_results.outputs.fcp) || 'N/A' }} | â‰¤2000ms | ${{ steps.parse_results.outputs.fcp != 'N/A' && (steps.parse_results.outputs.fcp <= '2000' && 'âœ…' || 'âŒ') || 'â“' }} |
            | ğŸ–¼ï¸ Largest Contentful Paint | ${{ steps.parse_results.outputs.lcp != 'N/A' && format('{0}ms', steps.parse_results.outputs.lcp) || 'N/A' }} | â‰¤2500ms | ${{ steps.parse_results.outputs.lcp != 'N/A' && (steps.parse_results.outputs.lcp <= '2500' && 'âœ…' || 'âŒ') || 'â“' }} |
            | ğŸ“ Cumulative Layout Shift | ${{ steps.parse_results.outputs.cls != 'N/A' && steps.parse_results.outputs.cls || 'N/A' }} | â‰¤0.1 | ${{ steps.parse_results.outputs.cls != 'N/A' && (steps.parse_results.outputs.cls <= '0.1' && 'âœ…' || 'âŒ') || 'â“' }} |

            ### ğŸ“‹ Assertion Results

            - âœ… **Passed:** ${{ steps.parse_results.outputs.pass_count }} assertions
            - âš ï¸ **Warnings:** ${{ steps.parse_results.outputs.warn_count }} assertions  
            - âŒ **Failed:** ${{ steps.parse_results.outputs.error_count }} assertions
            ${{ steps.parse_results.outputs.budget_violations > '0' && format('- ğŸ’° **Budget violations:** {0}', steps.parse_results.outputs.budget_violations) || '' }}

            ### ğŸ”— Detailed Reports

            ${{ steps.parse_results.outputs.formatted_links != '' && format('- ğŸ“Š [View interactive reports]({0})', steps.parse_results.outputs.formatted_links) || '- ğŸ“Š Interactive reports not available' }}
            - âœ… Check PR status checks for pass/fail details
            - ğŸ“„ Download HTML reports from job artifacts

            **Pages analyzed:**
            - ğŸ  Home page (`/`)
            - ğŸ‘¤ Over mij (`/over-mij`)
            - ğŸ¯ Aanpak (`/aanpak`)
            - ğŸ’¼ Coaching (`/coaching`)
            - ğŸ“§ Contact (`/contact`)

            ---
            <details>
            <summary>ğŸ“– Understanding the scores</summary>

            - **Performance** (Target: â‰¥80): Measures loading speed and runtime performance
            - **Accessibility** (Target: â‰¥95): Ensures the site is usable by people with disabilities
            - **SEO** (Target: â‰¥90): Checks search engine optimization best practices  
            - **Best Practices** (Target: â‰¥90): Follows web development best practices

            *This comment updates automatically on each push.*
            </details>
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: 'âš ï¸ Fallback notification (no PR found)'
        if: always() && steps.get_pr.outputs.pr_number == ''
        run: |
          echo "## âš ï¸ Lighthouse Results Available" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Could not post comment to PR, but Lighthouse analysis completed:" >> $GITHUB_STEP_SUMMARY
          echo "- **Status:** ${{ steps.parse_results.outputs.overall_status }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Failed assertions:** ${{ steps.parse_results.outputs.error_count }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Budget violations:** ${{ steps.parse_results.outputs.budget_violations }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Preview URL:** ${{ steps.get_url.outputs.preview-url }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Check job artifacts for detailed HTML reports." >> $GITHUB_STEP_SUMMARY

      - name: 'ğŸ“Š Display Lighthouse summary'
        if: always()
        run: |
          echo "## ğŸš€ Lighthouse Performance Report" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Preview URL:** ${{ steps.get_url.outputs.preview-url }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Lighthouse reports have been uploaded as artifacts and are available in the PR status checks." >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "ğŸ“ˆ **View detailed reports:**" >> $GITHUB_STEP_SUMMARY
          echo "- Check the PR status checks for individual page results" >> $GITHUB_STEP_SUMMARY
          echo "- Download HTML reports from job artifacts" >> $GITHUB_STEP_SUMMARY
          if [[ "${{ steps.lhci.outputs.links }}" != "" ]]; then
            echo "- [Temporary public reports](${{ steps.lhci.outputs.links }})" >> $GITHUB_STEP_SUMMARY
          fi
