name: 'Lighthouse (PR)'

on: deployment_status

concurrency:
  group: lhci-${{ github.event.deployment.id }}
  cancel-in-progress: true

permissions:
  contents: read
  deployments: read
  pull-requests: write
  issues: write

jobs:
  lighthouse:
    name: 'Lighthouse CI (Preview)'
    runs-on: ubuntu-latest
    timeout-minutes: 25
    continue-on-error: true
    if: |
      github.event.deployment_status.state == 'success' &&
      contains(github.event.deployment.environment, 'Preview') &&
      !contains(github.event.deployment.environment, 'Production') &&
      !contains(github.event.deployment.environment, 'main')

    env:
      VERCEL_AUTOMATION_BYPASS_SECRET: ${{ secrets.VERCEL_AUTOMATION_BYPASS_SECRET }}

    steps:
      - name: 'Checkout code'
        uses: actions/checkout@v5
      - name: 'âš™ï¸ Setup Environment'
        uses: ./.github/actions/setup
        with:
          node-version: '22'
          pnpm-version: '10.15.1'
          working-directory: ''

      - name: 'ğŸ”— Resolve preview URL (environment_url)'
        id: url
        shell: bash
        run: |
          set -euo pipefail
          url="${{ github.event.deployment_status.environment_url || '' }}"

          echo "ğŸ” Raw environment_url: $url"

          # Handle Vercel SSO redirects
          if [[ "$url" == *"vercel.com/login"* || "$url" == *"sso-api"* ]]; then
            if [[ "$url" =~ url=([^&]+) ]]; then
              enc="${BASH_REMATCH[1]}"
              url="$(python3 -c "import sys,urllib.parse;print(urllib.parse.unquote(sys.argv[1]))" "$enc")"
              echo "ğŸ” Decoded SSO URL: $url"
            fi
          fi

          # Validate it's a valid URL
          [[ "$url" =~ ^https?:// ]] || { echo "âŒ No valid environment_url found"; exit 1; }

          # Check if this is the studio URL (we don't want to test the CMS)
          if [[ "$url" == *"studio-leenders-coaching"* ]]; then
            echo "âš ï¸ Warning: This appears to be a studio deployment URL"
            echo "   Studio URL: $url"
            echo "   This workflow should test the main app, not the CMS"
            echo "   Consider checking your Vercel project configuration"
            
            # Try to construct the main app preview URL
            if [[ "$url" =~ ^https://studio-leenders-coaching-([^.]+)\.vercel\.app ]]; then
              branch_suffix="${BASH_REMATCH[1]}"
              main_app_url="https://leenders-coaching-${branch_suffix}.vercel.app"
              echo "ğŸ”„ Attempting to use main app URL: $main_app_url"
              url="$main_app_url"
            fi
          fi

          echo "âœ… Preview URL resolved: $url"
          echo "preview_url=$url" >> "$GITHUB_OUTPUT"

          # Debug deployment context
          echo "ğŸ” Deployment context:"
          echo "   Environment: ${{ github.event.deployment.environment }}"
          echo "   Project: ${{ github.event.deployment.environment_url }}"
          echo "   Commit SHA: ${{ github.event.deployment.sha }}"
          echo "   Ref: ${{ github.event.deployment.ref }}"

      - name: 'ğŸ§ª Test preview URL accessibility'
        run: |
          set -euo pipefail
          preview_url="${{ steps.url.outputs.preview_url }}"

          echo "ğŸ” Testing preview URL accessibility:"
          echo "  Base URL: $preview_url"

                    # Wait for preview deployment to be ready (max 2 minutes)
          echo "â³ Waiting for preview deployment to be ready..."
          max_attempts=12
          attempt=1

          while [[ $attempt -le $max_attempts ]]; do
            echo "  Attempt $attempt/$max_attempts..."
            
            # Test with bypass headers if available
            bypass_secret="${{ secrets.VERCEL_AUTOMATION_BYPASS_SECRET }}"
            if [[ -n "$bypass_secret" ]]; then
              echo "    Using Vercel automation bypass headers..."
              code=$(curl -s -o /dev/null -w "%{http_code}" \
                --max-time 30 --retry 2 --retry-delay 2 \
                -H "x-vercel-protection-bypass: $bypass_secret" \
                -H "x-vercel-set-bypass-cookie: true" \
                "$preview_url")
            else
              echo "    No bypass secret available, testing without headers..."
              code=$(curl -s -o /dev/null -w "%{http_code}" \
                --max-time 30 --retry 2 --retry-delay 2 \
                "$preview_url")
            fi
            
            if [[ "$code" -ge 200 && "$code" -lt 400 ]]; then
              echo "âœ… Base URL accessible (HTTP $code)"
              break
            else
              echo "âš ï¸ Base URL returned HTTP $code (attempt $attempt/$max_attempts)"
              if [[ $attempt -eq $max_attempts ]]; then
                echo "âŒ Preview deployment not ready after $max_attempts attempts"
                echo "   This suggests the preview deployment may have failed or is still building"
                echo "   Or the Vercel automation bypass is not working correctly"
                exit 1
              fi
              echo "   Waiting 10 seconds before retry..."
              sleep 10
              attempt=$((attempt + 1))
            fi
          done

          # Test a few key pages
          test_pages=("/over-mij" "/aanpak" "/coaching" "/contact")
          for page in "${test_pages[@]}"; do
            echo "  Testing: $page"
            
            # Test with bypass headers if available
            bypass_secret="${{ secrets.VERCEL_AUTOMATION_BYPASS_SECRET }}"
            if [[ -n "$bypass_secret" ]]; then
              page_code=$(curl -s -o /dev/null -w "%{http_code}" \
                --max-time 30 --retry 2 --retry-delay 2 \
                -H "x-vercel-protection-bypass: $bypass_secret" \
                -H "x-vercel-set-bypass-cookie: true" \
                "$preview_url$page")
            else
              page_code=$(curl -s -o /dev/null -w "%{http_code}" \
                --max-time 30 --retry 2 --retry-delay 2 \
                "$preview_url$page")
            fi
            
            if [[ "$page_code" -ge 200 && "$page_code" -lt 400 ]]; then
              echo "âœ… $page accessible (HTTP $page_code)"
            else
              echo "âš ï¸ $page returned HTTP $page_code (may not exist in preview)"
            fi
          done

          echo "ğŸ¯ Preview URL accessibility check completed"

      - name: 'ğŸ” Debug Environment Variables'
        run: |
          echo "ğŸ” Debugging environment variables:"
          echo "LHCI_FORM_FACTOR: mobile"
          echo "VERCEL_AUTOMATION_BYPASS_SECRET: ${VERCEL_AUTOMATION_BYPASS_SECRET:0:8}..." # Show first 8 chars
          echo "Has bypass secret: ${{ env.VERCEL_AUTOMATION_BYPASS_SECRET != '' }}"
          echo "Bypass secret length: ${#VERCEL_AUTOMATION_BYPASS_SECRET}"
          echo "Bypass secret first 16 chars: ${VERCEL_AUTOMATION_BYPASS_SECRET:0:16}..."
          echo ""
          echo "Testing bypass headers manually..."

          # Test the bypass headers manually
          preview_url="${{ steps.url.outputs.preview_url }}"
          bypass_secret="${{ secrets.VERCEL_AUTOMATION_BYPASS_SECRET }}"
          if [[ -n "$bypass_secret" ]]; then
            echo "Testing with bypass headers:"
            echo "  URL: $preview_url"
            echo "  Headers: x-vercel-protection-bypass: ${bypass_secret:0:8}..."
            
            # Test with bypass headers
            response=$(curl -s -o /dev/null -w "%{http_code}" \
              --max-time 30 \
              -H "x-vercel-protection-bypass: $bypass_secret" \
              -H "x-vercel-set-bypass-cookie: true" \
              "$preview_url")
            
            echo "  Response with bypass headers: HTTP $response"
          else
            echo "âŒ No bypass secret found!"
          fi

      - name: 'ğŸš€ Run Lighthouse CI'
        id: lhci
        uses: treosh/lighthouse-ci-action@v12
        with:
          urls: |
            ${{ steps.url.outputs.preview_url }}
            ${{ steps.url.outputs.preview_url }}/over-mij
            ${{ steps.url.outputs.preview_url }}/aanpak
            ${{ steps.url.outputs.preview_url }}/coaching
            ${{ steps.url.outputs.preview_url }}/contact
          configPath: packages/leenders-coaching-nl/lighthouserc.ci.cjs
          budgetPath: packages/leenders-coaching-nl/budget.json
          uploadArtifacts: true
          temporaryPublicStorage: true
        env:
          LHCI_FORM_FACTOR: mobile
          LHCI_GITHUB_APP_TOKEN: ${{ secrets.LHCI_GITHUB_APP_TOKEN }}

      - name: 'ğŸ“Š Parse Lighthouse results'
        id: parse
        if: always()
        shell: bash
        run: |
          set -euo pipefail
          command -v jq >/dev/null 2>&1 || { sudo apt-get update -y >/dev/null 2>&1 && sudo apt-get install -y jq -y >/dev/null 2>&1; }

          results_dir="${{ steps.lhci.outputs.resultsPath }}"
          assertion_file="$results_dir/assertion-results.json"

          # defaults
          echo "errc=0"   >> $GITHUB_OUTPUT
          echo "warnc=0"  >> $GITHUB_OUTPUT
          echo "passc=0"  >> $GITHUB_OUTPUT

          # assertions counts (if file exists) + details table
          if [[ -f "$assertion_file" ]]; then
            errc=$(jq '[.[] | select(.level=="error")] | length' "$assertion_file")
            warnc=$(jq '[.[] | select(.level=="warn")]  | length' "$assertion_file")
            passc=$(jq '[.[] | select(.level=="pass")]  | length' "$assertion_file")
            echo "errc=$errc"  >> $GITHUB_OUTPUT
            echo "warnc=$warnc" >> $GITHUB_OUTPUT
            echo "passc=$passc" >> $GITHUB_OUTPUT

            rows=$(jq -r '
              [ .[] | select(.level!="pass")
                | { level, id: (.id // .auditId // "â€”"),
                    url: (.url // "â€”"),
                    op: (.result.operator // "â€”"),
                    exp: (.result.expected // "â€”"),
                    act: (.result.actual // "â€”") } ] 
              | .[:25]
              | map("| \(.level) | \(.id) | \(.exp) | \(.act) | \(.op) | \(.url) |")
              | .[]
            ' "$assertion_file")

            {
              echo "assert_md<<EOF"
              echo "| Level | Check | Expected | Actual | Operator | URL |"
              echo "|---|---|---|---|---|---|"
              if [[ -n "$rows" ]]; then
                printf '%s\n' "$rows"
              else
                echo "| - | - | - | - | - | - |"
              fi
              echo "EOF"
            } >> "$GITHUB_OUTPUT"
          else
            {
              echo "assert_md<<EOF"
              echo "_No assertions file found._"
              echo "EOF"
            } >> "$GITHUB_OUTPUT"
          fi

          # derive category scores from raw LHRs (robust)
          if [[ -n "$results_dir" && -d "$results_dir" ]]; then
            shopt -s nullglob
            lhrs=("$results_dir"/lhr-*.json)
          else
            lhrs=()
          fi

          if [[ ${#lhrs[@]} -eq 0 ]]; then
            echo "perf=N/A" >> $GITHUB_OUTPUT
            echo "a11y=N/A" >> $GITHUB_OUTPUT
            echo "seo=N/A"  >> $GITHUB_OUTPUT
            echo "bp=N/A"   >> $GITHUB_OUTPUT
            echo "overall=âš ï¸ NO RESULTS" >> $GITHUB_OUTPUT
            echo "âŒ No Lighthouse results found. This usually means:"
            echo "   1. Preview deployment failed or is still building"
            echo "   2. URLs returned 404 errors"
            echo "   3. Lighthouse CI failed to collect data"
          else
            readarray -t vals < <(jq -s '
              def avg: (length as $n | if $n==0 then null else (add / $n) end);
              {
                perf: (map(try .categories.performance.score catch null) | map(select(.!=null)) | avg),
                a11y: (map(try .categories.accessibility.score catch null) | map(select(.!=null)) | avg),
                seo:  (map(try .categories.seo.score catch null) | map(select(.!=null)) | avg),
                bp:   (map(try .categories["best-practices"].score catch null) | map(select(.!=null)) | avg)
              } | [.perf,.a11y,.seo,.bp] | map(if .==null then "N/A" else . end) | .[]
            ' "${lhrs[@]}")

            to_pct () { awk -v v="$1" 'BEGIN{printf "%.0f", v*100}'; }
            perf="${vals[0]}"; a11y="${vals[1]}"; seo="${vals[2]}"; bp="${vals[3]}"

            [[ "$perf" != "N/A" ]] && echo "perf=$(to_pct "$perf")" >> $GITHUB_OUTPUT || echo "perf=N/A" >> $GITHUB_OUTPUT
            [[ "$a11y" != "N/A" ]] && echo "a11y=$(to_pct "$a11y")" >> $GITHUB_OUTPUT || echo "a11y=N/A" >> $GITHUB_OUTPUT
            [[ "$seo"  != "N/A" ]] && echo "seo=$(to_pct "$seo")"   >> $GITHUB_OUTPUT || echo "seo=N/A"  >> $GITHUB_OUTPUT
            [[ "$bp"   != "N/A" ]] && echo "bp=$(to_pct "$bp")"     >> $GITHUB_OUTPUT || echo "bp=N/A"   >> $GITHUB_OUTPUT

            if [[ -f "$assertion_file" ]] && [[ "${errc:-0}" -gt 0 ]]; then
              echo "overall=âŒ FAILED" >> $GITHUB_OUTPUT
            else
              echo "overall=âœ… PASSED" >> $GITHUB_OUTPUT
            fi
          fi

          # Note: Links are processed in the table step for per-page report links

      - name: 'ğŸ§¾ Build per-page tables (categories + vitals)'
        id: table
        if: always()
        shell: bash
        run: |
          set -euo pipefail
          command -v jq >/dev/null 2>&1 || { sudo apt-get update -y >/dev/null 2>&1 && sudo apt-get install -y jq -y >/dev/null 2>&1; }

          results_dir="${{ steps.lhci.outputs.resultsPath }}"
          base="${{ steps.url.outputs.preview_url }}"
          ordered_urls=("$base" "$base/over-mij" "$base/aanpak" "$base/coaching" "$base/contact")

          # --- CATEGORY SCORES MAP: url -> {p,a,s,b} ---
          scores_json="$(jq -sr '
            def norm(u):
              if u==null then null else (u | sub("[?#].*$"; "") | sub("/$"; "")) end;
            def key(x): norm(x.finalDisplayedUrl // x.finalUrl // x.requestedUrl);
            def avg: (length as $n | if $n==0 then null else (add / $n) end);
            sort_by(key(.))
            | group_by(key(.))
            | map(. as $g | {
                url: ($g | first | key(.)),
                p: ([ $g[] | try .categories.performance.score        catch empty ] | map(select(.!=null)) | avg),
                a: ([ $g[] | try .categories.accessibility.score      catch empty ] | map(select(.!=null)) | avg),
                s: ([ $g[] | try .categories.seo.score                catch empty ] | map(select(.!=null)) | avg),
                b: ([ $g[] | try .categories["best-practices"].score catch empty ] | map(select(.!=null)) | avg)
              })
            | map({ (.url): {p:.p,a:.a,s:.s,b:.b} })
            | add // {}
          ' "$results_dir"/lhr-*.json)"

          fpct() { v="$1"; if [[ "$v" == "null" || -z "$v" ]]; then echo "N/A"; else awk -v n="$v" 'BEGIN{printf "%.0f", n*100}'; fi; }

          # --- LINKS (report urls) ---
          raw_links='${{ steps.lhci.outputs.links }}'
          declare -A url2link=()
          declare -a link_list=()
          if [[ -n "$raw_links" && "$raw_links" != "null" ]]; then
            if echo "$raw_links" | grep -q '^{'; then
              while IFS=$'\t' read -r k v; do
                k="${k%%[\?#]*}"; k="${k%/}"
                url2link["$k"]="$v"
              done < <(printf '%s' "$raw_links" | jq -r 'to_entries[] | [.key,.value] | @tsv')
            elif echo "$raw_links" | grep -q '^\s*\['; then
              mapfile -t link_list < <(printf '%s' "$raw_links" | jq -r '.[]')
            else
              mapfile -t link_list < <(printf '%s\n' "$raw_links")
            fi
          fi

          # --- Build categories table ---
          table="| Page | Perf | A11y | SEO | BP | Report |"$'\n'"|---|---:|---:|---:|---:|---|"$'\n'
          idx=0
          for u in "${ordered_urls[@]}"; do
            if [[ "$u" == */ ]]; then alt="${u%/}"; else alt="$u/"; fi
            key="${u%/}" ; altkey="${alt%/}"

            p=$(jq -r --arg k "$key" --arg a "$altkey" -n --argjson m "$scores_json" '($m[$k].p // $m[$a].p // "null")')
            a=$(jq -r --arg k "$key" --arg a "$altkey" -n --argjson m "$scores_json" '($m[$k].a // $m[$a].a // "null")')
            s=$(jq -r --arg k "$key" --arg a "$altkey" -n --argjson m "$scores_json" '($m[$k].s // $m[$a].s // "null")')
            b=$(jq -r --arg k "$key" --arg a "$altkey" -n --argjson m "$scores_json" '($m[$k].b // $m[$a].b // "null")')

            ps=$(fpct "$p"); as=$(fpct "$a"); ss=$(fpct "$s"); bs=$(fpct "$b")

            link="${url2link[$key]-}"
            [[ -z "$link" ]] && link="${url2link[$altkey]-}"
            if [[ -z "$link" && ${#link_list[@]} -gt 0 ]]; then link="${link_list[$idx]-}"; fi
            [[ -n "$link" ]] && report_cell="[Report]($link)" || report_cell="-"

            table+="| $u | $ps | $as | $ss | $bs | $report_cell |"$'\n'
            idx=$((idx+1))
          done

          {
            echo "md<<EOF"
            echo "$table"
            echo "EOF"
          } >> "$GITHUB_OUTPUT"

          # --- VITALS MAP: url -> {lcp,cls,tbt,fcp,si,tti,bytes,reqs} ---
          metrics_json="$(jq -sr '
            def norm(u): if u==null then null else (u | sub("[?#].*$"; "") | sub("/$"; "")) end;
            def key(x): norm(x.finalDisplayedUrl // x.finalUrl // x.requestedUrl);
            def avg: (length as $n | if $n==0 then null else (add / $n) end);
            sort_by(key(.))
            | group_by(key(.))
            | map(. as $g | {
                url: ($g | first | key(.)),
                lcp: ([ $g[] | try .audits["largest-contentful-paint"].numericValue catch empty ] | map(select(.!=null)) | avg),
                cls: ([ $g[] | try .audits["cumulative-layout-shift"].numericValue catch empty ] | map(select(.!=null)) | avg),
                tbt: ([ $g[] | try .audits["total-blocking-time"].numericValue catch empty ] | map(select(.!=null)) | avg),
                fcp: ([ $g[] | try .audits["first-contentful-paint"].numericValue catch empty ] | map(select(.!=null)) | avg),
                si:  ([ $g[] | try .audits["speed-index"].numericValue catch empty ] | map(select(.!=null)) | avg),
                tti: ([ $g[] | try .audits["interactive"].numericValue catch empty ] | map(select(.!=null)) | avg),
                bytes: ([ $g[] | try .audits["total-byte-weight"].numericValue catch empty ] | map(select(.!=null)) | avg),
                reqs: ([ $g[] | try (.audits["network-requests"].details.items | length) catch empty ] | map(select(.!=null)) | avg)
              })
            | map({ (.url): {lcp:.lcp,cls:.cls,tbt:.tbt,fcp:.fcp,si:.si,tti:.tti,bytes:.bytes,reqs:.reqs} })
            | add // {}
          ' "$results_dir"/lhr-*.json)"

          ms() { v="$1"; if [[ "$v" == "null" || -z "$v" ]]; then echo "N/A"; else awk -v n="$v" 'BEGIN{printf "%.0f", n}'; fi; }
          kb() { v="$1"; if [[ "$v" == "null" || -z "$v" ]]; then echo "N/A"; else awk -v n="$v" 'BEGIN{printf "%.0f", n/1024}'; fi; }
          num() { v="$1"; if [[ "$v" == "null" || -z "$v" ]]; then echo "N/A"; else awk -v n="$v" 'BEGIN{printf "%.0f", n}'; fi; }

          vt="| Page | LCP (ms) | CLS | TBT (ms) | FCP (ms) | SI (ms) | TTI (ms) | Req | Bytes (KB) |"$'\n'"|---|---:|---:|---:|---:|---:|---:|---:|---:|"$'\n'
          for u in "${ordered_urls[@]}"; do
            if [[ "$u" == */ ]]; then alt="${u%/}"; else alt="$u/"; fi
            key="${u%/}" ; altkey="${alt%/}"

            lcp=$(jq -r --arg k "$key" --arg a "$altkey" -n --argjson m "$metrics_json" '($m[$k].lcp // $m[$a].lcp // "null")')
            cls=$(jq -r --arg k "$key" --arg a "$altkey" -n --argjson m "$metrics_json" '($m[$k].cls // $m[$a].cls // "null")')
            tbt=$(jq -r --arg k "$key" --arg a "$altkey" -n --argjson m "$metrics_json" '($m[$k].tbt // $m[$a].tbt // "null")')
            fcp=$(jq -r --arg k "$key" --arg a "$altkey" -n --argjson m "$metrics_json" '($m[$k].fcp // $m[$a].fcp // "null")')
            si=$(jq -r  --arg k "$key" --arg a "$altkey" -n --argjson m "$metrics_json" '($m[$k].si  // $m[$a].si  // "null")')
            tti=$(jq -r --arg k "$key" --arg a "$altkey" -n --argjson m "$metrics_json" '($m[$k].tti // $m[$a].tti // "null")')
            bytes=$(jq -r --arg k "$key" --arg a "$altkey" -n --argjson m "$metrics_json" '($m[$k].bytes // $m[$a].bytes // "null")')
            reqs=$(jq -r  --arg k "$key" --arg a "$altkey" -n --argjson m "$metrics_json" '($m[$k].reqs // $m[$a].reqs // "null")')

            vt+="| $u | $(ms "$lcp") | $(printf '%.3f' "${cls:-0}" 2>/dev/null || echo 'N/A') | $(ms "$tbt") | $(ms "$fcp") | $(ms "$si") | $(ms "$tti") | $(num "$reqs") | $(kb "$bytes") |"$'\n'
          done

          {
            echo "vitals_md<<EOF"
            echo "$vt"
            echo "EOF"
          } >> "$GITHUB_OUTPUT"

      - name: 'ğŸ” Resolve PR number'
        id: pr
        if: always()
        env:
          REPO: ${{ github.repository }}
          SHA: ${{ github.event.deployment.sha }}
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        shell: bash
        run: |
          set -euo pipefail
          command -v jq >/dev/null 2>&1 || { sudo apt-get update -y >/dev/null 2>&1 && sudo apt-get install -y jq >/dev/null 2>&1; }
          json=$(curl -sS -H "Authorization: token ${GH_TOKEN}" -H "Accept: application/vnd.github+json" \
                 "https://api.github.com/repos/${REPO}/commits/${SHA}/pulls")
          pr=$(echo "$json" | jq -r 'map(select(.state!="closed")) | first | .number // empty')
          echo "number=$pr" >> $GITHUB_OUTPUT
          [[ -n "$pr" ]] && echo "Found PR #$pr" || echo "No open PR found for $SHA"

      - name: 'ğŸ’¬ Sticky Lighthouse comment'
        if: always() && steps.pr.outputs.number != ''
        uses: marocchino/sticky-pull-request-comment@v2
        with:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          header: lighthouse-report
          number: ${{ steps.pr.outputs.number }}
          message: |
            ## ğŸš€ Lighthouse Performance Report
            **Preview URL:** ${{ steps.url.outputs.preview_url }}
            **Status:** ${{ steps.parse.outputs.overall }}

            ### Category Scores
            <details>
            <summary>ğŸ“Š Category Scores</summary>

            ${{ steps.table.outputs.md }}
            </details>

            ### Core Metrics
            <details>
            <summary>ğŸš€ Core Web Vitals</summary>

            ${{ steps.table.outputs.vitals_md }}
            </details>

            **Assertions:** âœ… ${{ steps.parse.outputs.passc }} Â· âš ï¸ ${{ steps.parse.outputs.warnc }} Â· âŒ ${{ steps.parse.outputs.errc }}

            <details>
            <summary>ğŸ” Assertion Details</summary>

            ${{ steps.parse.outputs.assert_md }}
            </details>

            *Generated by GitHub Actions Lighthouse*

      - name: 'ğŸ“‹ Job summary'
        if: always()
        shell: bash
        run: |
          {
            echo "## ğŸš€ Lighthouse (Preview)";
            echo "- URL: ${{ steps.url.outputs.preview_url }}";
            echo "- Status: ${{ steps.parse.outputs.overall }}";
            echo "";
            echo "### Category Scores";
            echo "<details>";
            echo "<summary>ğŸ“Š Category Scores</summary>";
            echo "";
            echo "${{ steps.table.outputs.md }}";
            echo "</details>";
            echo "";
            echo "### Core Metrics";
            echo "<details>";
            echo "<summary>ğŸš€ Core Web Vitals</summary>";
            echo "";
            echo "${{ steps.table.outputs.vitals_md }}";
            echo "</details>";
            echo "";
            echo "**Assertions:** âœ… ${{ steps.parse.outputs.passc }} Â· âš ï¸ ${{ steps.parse.outputs.warnc }} Â· âŒ ${{ steps.parse.outputs.errc }}";
            echo "";
            echo "<details>";
            echo "<summary>ğŸ” Assertion Details</summary>";
            echo "";
            echo "${{ steps.parse.outputs.assert_md }}";
            echo "</details>";
          } >> $GITHUB_STEP_SUMMARY
